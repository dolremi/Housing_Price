{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The primary dataset generation\n",
    "This notebook we will create datasets that can be used to feature selection. The major procedure includes filling out the missing values, drop the features that majority of them are missing, do the log transform for the numerical features, generate the interaction features. For categorical features, there are three different approaches, one is the regular [One Hot Encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), the other approach is [Empirical Bayesian Method](http://helios.mm.di.uoa.gr/~rouvas/ssi/sigkdd/sigkdd.vol3.1/barreca.pdf) and last one is to encoding according to ordering [based on mean of the target value](https://www.kaggle.com/dgawlik/house-prices-eda) .We can generate three different ways to generate the dataset. After all the procedure, we will do the standardization to get mearn 0 and standard deviation of 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.preprocessing import Imputer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = \"../../data/train.csv\"\n",
    "test = \"../../data/test.csv\"\n",
    "modified = \"../../data/modified/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(training)\n",
    "df_test = pd.read_csv(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "Those data `with more than 4000 square feet` can be considered as outlier according to the [paper](https://ww2.amstat.org/publications/jse/v19n3/decock.pdf). We can remove them in the training data at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.GrLivArea < 4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "We can drop some features that most of which are missing values, which doesn't contribute much to our target value -- housing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_missing = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.drop(drop_missing, inplace=True, axis=1)\n",
    "df_test.drop(drop_missing, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_specific(data, spec):\n",
    "    col = []\n",
    "    for key, val in spec.items():\n",
    "        if isinstance(val, list):\n",
    "            for item in val:\n",
    "                if item in data.columns.values:\n",
    "                    data[item].fillna(key, inplace=True)\n",
    "                    print(\"Column {0} 's empty value has been replaced by {1}\".format(item, key))\n",
    "                    col.append(item)\n",
    "                else:\n",
    "                    print(\"{0} is not a column in the dataset.\".format(item))\n",
    "        else:\n",
    "            print(\"To replace NA values with {0}, a list needs to be specified.\".format(key))\n",
    "    print(\"\\n Now the columns have been updated:\")\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fill_dict = {\"NoBsmt\": [\"BsmtFinType1\", \"BsmtCond\", \"BsmtFinType2\", \"BsmtExposure\", \"BsmtQual\"],\n",
    "             \"NoGarage\": [\"GarageCond\", \"GarageQual\", \"GarageFinish\", \"GarageType\"],\n",
    "             \"NoPool\": [\"PoolQC\"],\n",
    "             \"NoFirePlace\": [\"FireplaceQu\"],\n",
    "             \"NoFence\":[\"Fence\"],\n",
    "             \"NoAccess\": [\"Alley\"],\n",
    "             \"None\": [\"MiscFeature\", \"MasVnrType\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fence is not a column in the dataset.\n",
      "PoolQC is not a column in the dataset.\n",
      "Column FireplaceQu 's empty value has been replaced by NoFirePlace\n",
      "MiscFeature is not a column in the dataset.\n",
      "Column MasVnrType 's empty value has been replaced by None\n",
      "Column BsmtFinType1 's empty value has been replaced by NoBsmt\n",
      "Column BsmtCond 's empty value has been replaced by NoBsmt\n",
      "Column BsmtFinType2 's empty value has been replaced by NoBsmt\n",
      "Column BsmtExposure 's empty value has been replaced by NoBsmt\n",
      "Column BsmtQual 's empty value has been replaced by NoBsmt\n",
      "Alley is not a column in the dataset.\n",
      "Column GarageCond 's empty value has been replaced by NoGarage\n",
      "Column GarageQual 's empty value has been replaced by NoGarage\n",
      "Column GarageFinish 's empty value has been replaced by NoGarage\n",
      "Column GarageType 's empty value has been replaced by NoGarage\n",
      "\n",
      " Now the columns have been updated:\n",
      "['FireplaceQu', 'MasVnrType', 'BsmtFinType1', 'BsmtCond', 'BsmtFinType2', 'BsmtExposure', 'BsmtQual', 'GarageCond', 'GarageQual', 'GarageFinish', 'GarageType']\n"
     ]
    }
   ],
   "source": [
    "fill_specific(df_train,fill_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fence is not a column in the dataset.\n",
      "PoolQC is not a column in the dataset.\n",
      "Column FireplaceQu 's empty value has been replaced by NoFirePlace\n",
      "MiscFeature is not a column in the dataset.\n",
      "Column MasVnrType 's empty value has been replaced by None\n",
      "Column BsmtFinType1 's empty value has been replaced by NoBsmt\n",
      "Column BsmtCond 's empty value has been replaced by NoBsmt\n",
      "Column BsmtFinType2 's empty value has been replaced by NoBsmt\n",
      "Column BsmtExposure 's empty value has been replaced by NoBsmt\n",
      "Column BsmtQual 's empty value has been replaced by NoBsmt\n",
      "Alley is not a column in the dataset.\n",
      "Column GarageCond 's empty value has been replaced by NoGarage\n",
      "Column GarageQual 's empty value has been replaced by NoGarage\n",
      "Column GarageFinish 's empty value has been replaced by NoGarage\n",
      "Column GarageType 's empty value has been replaced by NoGarage\n",
      "\n",
      " Now the columns have been updated:\n",
      "['FireplaceQu', 'MasVnrType', 'BsmtFinType1', 'BsmtCond', 'BsmtFinType2', 'BsmtExposure', 'BsmtQual', 'GarageCond', 'GarageQual', 'GarageFinish', 'GarageType']\n"
     ]
    }
   ],
   "source": [
    "fill_specific(df_test, fill_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_empty(input_data, value=0):\n",
    "    \"\"\"\n",
    "    Find the all the columns with empty values with descending order, where the number of the empty values is larger\n",
    "    than value\n",
    "    :param input_data: the input data as a Pandas DataFrame\n",
    "    :param value: the minimum number of the empty values in the column\n",
    "    :return: A Pandas Series having empty values with column name and number of empty values\n",
    "    \"\"\"\n",
    "    if not isinstance(input_data, pd.DataFrame):\n",
    "        raise TypeError(\"Input data is not a valid Pandas DataFrame\")\n",
    "    columns = input_data.isnull().sum()\n",
    "    columns = columns[columns > value]\n",
    "    columns.sort_values(ascending=False, inplace=True)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def current_empty(input_data):\n",
    "    \"\"\"\n",
    "    Compute the list of the column names with empty values\n",
    "    :param input_data: the input data as a Pandas DataFrame\n",
    "    :return: A list of the column names with empty values\n",
    "    \"\"\"\n",
    "    cols = list(calculate_empty(input_data).index)\n",
    "    if cols:\n",
    "        print(\"Now the column name(s) that have empty values are:\")\n",
    "        print(calculate_empty(input_data))\n",
    "    else:\n",
    "        print(\"There are no empty values in the data.\")\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "LotFrontage    259\n",
      "GarageYrBlt     81\n",
      "MasVnrArea       8\n",
      "Electrical       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'GarageYrBlt', 'MasVnrArea', 'Electrical']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "LotFrontage     227\n",
      "GarageYrBlt      78\n",
      "MasVnrArea       15\n",
      "MSZoning          4\n",
      "Functional        2\n",
      "Utilities         2\n",
      "BsmtHalfBath      2\n",
      "BsmtFullBath      2\n",
      "BsmtFinSF1        1\n",
      "Exterior1st       1\n",
      "Exterior2nd       1\n",
      "SaleType          1\n",
      "BsmtFinSF2        1\n",
      "GarageArea        1\n",
      "TotalBsmtSF       1\n",
      "KitchenQual       1\n",
      "GarageCars        1\n",
      "BsmtUnfSF         1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'GarageYrBlt',\n",
       " 'MasVnrArea',\n",
       " 'MSZoning',\n",
       " 'Functional',\n",
       " 'Utilities',\n",
       " 'BsmtHalfBath',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtFinSF1',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'SaleType',\n",
       " 'BsmtFinSF2',\n",
       " 'GarageArea',\n",
       " 'TotalBsmtSF',\n",
       " 'KitchenQual',\n",
       " 'GarageCars',\n",
       " 'BsmtUnfSF']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage features\n",
    "There is one mising value in `GarageArea` and `GarageCars` in the test data. We can have a look at the garage type in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GarageType is Detchd, when the Garage Area is empty.\n"
     ]
    }
   ],
   "source": [
    "Garagetype = df_test.loc[df_test.GarageArea.isnull(),'GarageType']\n",
    "print (\"The GarageType is \" + Garagetype.values[0] +\n",
    "       \", when the Garage Area is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace the missing value with the median value of `GarageArea` and `GarageCars` when the `GarageType` is `Detchd`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_group(data, group):\n",
    "    \"\"\"\n",
    "    This function will go through the dictionary of group, for each column as key[0] has a value of key[1], it will\n",
    "    fill those columns' empty values in the corresponding list as the mode of the group in column key[0] with value\n",
    "    key[1] if it is category, or median of the group in column key[0] with value key[1] if it is a numeric one.\n",
    "    :param group: A dictionary has the key as the tuple of (col1, val1) and value as a list\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not isinstance(group, dict):\n",
    "        raise TypeError(\"A dictionary needs to be passed to specify how to fill empty values with group\")\n",
    "\n",
    "    col = []\n",
    "    value = 0\n",
    "    for key, val in group.items():\n",
    "        if key[0] in data.columns.values:\n",
    "            if isinstance(val, list):\n",
    "                for item in val:\n",
    "                    if item in data.columns.values:\n",
    "                        if data[item].dtypes == \"object\":\n",
    "                            value = data.loc[data[key[0]] == key[1], item].mode()[0]\n",
    "                        else:\n",
    "                            value = data.loc[data[key[0]] == key[1], item].median()\n",
    "                        data[item].fillna(value, inplace=True)\n",
    "                        print(\"Now column {0} 's empty value has been replaced by {1}\".format(item, value))\n",
    "                        col.append(item)\n",
    "\n",
    "            else:\n",
    "                print(\"To replace {0}, a list needs to be specified.\".format(key[1]))\n",
    "\n",
    "        else:\n",
    "            print(\"{0} is not a column in the dataset.\".format(key[0]))\n",
    "    print(\"\\n Now the columns have been updated:\")\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = {(\"GarageType\", \"Detchd\"): [\"GarageArea\", \"GarageCars\"] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now column GarageArea 's empty value has been replaced by 384.0\n",
      "Now column GarageCars 's empty value has been replaced by 1.0\n",
      "\n",
      " Now the columns have been updated:\n",
      "['GarageArea', 'GarageCars']\n"
     ]
    }
   ],
   "source": [
    "fill_group(df_test,group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "LotFrontage     227\n",
      "GarageYrBlt      78\n",
      "MasVnrArea       15\n",
      "MSZoning          4\n",
      "Functional        2\n",
      "BsmtHalfBath      2\n",
      "BsmtFullBath      2\n",
      "Utilities         2\n",
      "SaleType          1\n",
      "KitchenQual       1\n",
      "TotalBsmtSF       1\n",
      "BsmtUnfSF         1\n",
      "BsmtFinSF2        1\n",
      "BsmtFinSF1        1\n",
      "Exterior2nd       1\n",
      "Exterior1st       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'GarageYrBlt',\n",
       " 'MasVnrArea',\n",
       " 'MSZoning',\n",
       " 'Functional',\n",
       " 'BsmtHalfBath',\n",
       " 'BsmtFullBath',\n",
       " 'Utilities',\n",
       " 'SaleType',\n",
       " 'KitchenQual',\n",
       " 'TotalBsmtSF',\n",
       " 'BsmtUnfSF',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtFinSF1',\n",
       " 'Exterior2nd',\n",
       " 'Exterior1st']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_value(data, matching):\n",
    "    if not isinstance(matching, dict):\n",
    "        raise TypeError(\"A dictionary needs to be passed to convert the columns.\")\n",
    "\n",
    "    col = []\n",
    "    for key, val in matching.items():\n",
    "        if isinstance(val, list):\n",
    "            for item in val:\n",
    "                if item[0] in data.columns.values and item[1] in data.columns.values:\n",
    "                    data.loc[data[item[0]] == key[0], item[1]] = key[1]\n",
    "                    col.append(item[1])\n",
    "                else:\n",
    "                    print(\"Please check the column names, {0} or {1} may not be a valid column name\".format(item[0],item[1]))\n",
    "        else:\n",
    "            print(\"The columns to convert need to be a list.\")\n",
    "    print(\"\\n Now the columns have been updated:\")\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value_matching = {\n",
    "    (\"NoBsmt\", 0): [(\"BsmtFinType1\", \"BsmtFinSF1\"), (\"BsmtFinType2\", \"BsmtFinSF2\"), (\"BsmtQual\", \"TotalBsmtSF\"),\n",
    "                    (\"BsmtQual\", \"BsmtUnfSF\")\n",
    "                    ],\n",
    "    (\"None\", 0):[(\"MasVnrType\",\"MasVnrArea\")],\n",
    "    (\"NoGarage\", 0) : [(\"GarageType\", \"GarageCars\"), (\"GarageType\", \"GarageArea\")],\n",
    "    (\"NoFirePlace\", 0): [(\"FireplaceQu\", \"Fireplaces\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Now the columns have been updated:\n",
      "['MasVnrArea', 'Fireplaces', 'GarageCars', 'GarageArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', 'BsmtUnfSF']\n"
     ]
    }
   ],
   "source": [
    "convert_value(df_train, value_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "LotFrontage    259\n",
      "GarageYrBlt     81\n",
      "Electrical       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'GarageYrBlt', 'Electrical']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Now the columns have been updated:\n",
      "['MasVnrArea', 'Fireplaces', 'GarageCars', 'GarageArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', 'BsmtUnfSF']\n"
     ]
    }
   ],
   "source": [
    "convert_value(df_test, value_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "LotFrontage     227\n",
      "GarageYrBlt      78\n",
      "MSZoning          4\n",
      "Functional        2\n",
      "BsmtHalfBath      2\n",
      "BsmtFullBath      2\n",
      "Utilities         2\n",
      "SaleType          1\n",
      "KitchenQual       1\n",
      "Exterior2nd       1\n",
      "Exterior1st       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'GarageYrBlt',\n",
       " 'MSZoning',\n",
       " 'Functional',\n",
       " 'BsmtHalfBath',\n",
       " 'BsmtFullBath',\n",
       " 'Utilities',\n",
       " 'SaleType',\n",
       " 'KitchenQual',\n",
       " 'Exterior2nd',\n",
       " 'Exterior1st']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage Year Built\n",
    "2216 of the 2919 houses have same year for for `GarageYrBlt` and `YearBuilt`.Replace any of the NAâ€™s for `GarageYrBlt` with the year from `YearBuilt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['GarageYrBlt'].fillna(df_train['YearBuilt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "LotFrontage    259\n",
      "Electrical       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'Electrical']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "LotFrontage     227\n",
      "MSZoning          4\n",
      "Functional        2\n",
      "BsmtHalfBath      2\n",
      "BsmtFullBath      2\n",
      "Utilities         2\n",
      "SaleType          1\n",
      "KitchenQual       1\n",
      "Exterior2nd       1\n",
      "Exterior1st       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'MSZoning',\n",
       " 'Functional',\n",
       " 'BsmtHalfBath',\n",
       " 'BsmtFullBath',\n",
       " 'Utilities',\n",
       " 'SaleType',\n",
       " 'KitchenQual',\n",
       " 'Exterior2nd',\n",
       " 'Exterior1st']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['GarageYrBlt'].fillna(df_test['YearBuilt'], inplace=True)\n",
    "current_empty(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotFrontage\n",
    "`LotFrontage` is the linear feet of street connected to property. We can explore its relations with `LotArea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38757021208207809"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['LotFrontage'].corr(df_train['LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6446084977757518"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['LotFrontage'].corr(df_test['LotArea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the relation between `LotFrontage` and  the root square of `LotArea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70300193477713013"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['LotFrontage'].corr(np.sqrt(df_test['LotArea']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58015981105630132"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['LotFrontage'].corr(np.sqrt(df_train['LotArea']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill the missing values of `LotFrontage` with the square root of `LotArea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['LotFrontage'].fillna(np.sqrt(df_train['LotArea']), inplace=True)\n",
    "df_test['LotFrontage'].fillna(np.sqrt(df_test['LotArea']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "Electrical    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Electrical']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the column name(s) that have empty values are:\n",
      "MSZoning        4\n",
      "Functional      2\n",
      "BsmtHalfBath    2\n",
      "BsmtFullBath    2\n",
      "Utilities       2\n",
      "SaleType        1\n",
      "KitchenQual     1\n",
      "Exterior2nd     1\n",
      "Exterior1st     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Functional',\n",
       " 'BsmtHalfBath',\n",
       " 'BsmtFullBath',\n",
       " 'Utilities',\n",
       " 'SaleType',\n",
       " 'KitchenQual',\n",
       " 'Exterior2nd',\n",
       " 'Exterior1st']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['Electrical'].fillna(df_train['Electrical'].value_counts().idxmax(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no empty values in the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placement = ['MSZoning','Functional','Utilities','SaleType','KitchenQual','Exterior2nd','Exterior1st']\n",
    "for feature in placement:\n",
    "    df_test[feature].fillna(df_train[feature].value_counts().idxmax(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medians = ['BsmtHalfBath','BsmtFullBath' ]\n",
    "for feature in medians:\n",
    "    df_test[feature].fillna(df_train[feature].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no empty values in the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_empty(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'MSSubClass': { 20: \"SubClass_20\",\n",
    "                     30: \"SubClass_30\",\n",
    "                     40: \"SubClass_40\",\n",
    "                     45: \"SubClass_45\",\n",
    "                     50: \"SubClass_50\",\n",
    "                     60: \"SubClass_60\",\n",
    "                     70: \"SubClass_70\",\n",
    "                     75: \"SubClass_75\",\n",
    "                     80: \"SubClass_80\",\n",
    "                     85: \"SubClass_85\",\n",
    "                     90: \"SubClass_90\",\n",
    "                     120: \"SubClass_120\",\n",
    "                     150: \"SubClass_150\",\n",
    "                     160: \"SubClass_160\",\n",
    "                     180: \"SubClass_180\",\n",
    "                     190: \"SubClass_190\"},\n",
    "    'MoSold': { 1:\"Jan\",\n",
    "                2:\"Feb\",\n",
    "                3:\"Mar\",\n",
    "                4:\"Apr\",\n",
    "                5:\"May\",\n",
    "                6:\"Jun\",\n",
    "                7: \"Jul\",\n",
    "                8: \"Aug\",\n",
    "                9:\"Sep\",\n",
    "               10:\"Oct\",\n",
    "               11:\"Nov\",\n",
    "               12:\"Dec\"}\n",
    "    }\n",
    "df_train.replace(mapping, inplace=True)\n",
    "df_test.replace(mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete = modified + \"raw_complete.pkl\"\n",
    "completed = {\"train\": df_train, \"test\": df_test}\n",
    "with open(complete, 'wb') as f:\n",
    "    pickle.dump(completed, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical features\n",
    "For some numerical features, we need to do logarithm transformation in order to fit into some models that assumes the features are gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "numerical = [f for f in df_train.columns.values if df_train.dtypes[f] != 'object' ]\n",
    "print(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['LotArea','LotFrontage','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','KitchenAbvGr']\n",
    "for f in features:\n",
    "    df_train[f] = np.log1p(df_train[f].values)\n",
    "    df_test[f] = np.log1p(df_test[f].values)\n",
    "df_train['SalePrice'] = np.log1p(df_train['SalePrice'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features\n",
    "There are several ways to encode categorical features for numerical numbers:\n",
    "* One Hot Encoder\n",
    "* Emperical Baysian Method\n",
    "* Encoding based on order of the average of the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'MoSold', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "categorical = [f for f in df_train.columns.values if df_train.dtypes[f] == 'object']\n",
    "print(categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_dummy = pd.get_dummies(df_train,columns=categorical)\n",
    "df_test_dummy = pd.get_dummies(df_test,columns=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "HotFile = modified + \"OneHotRaw.pkl\"\n",
    "OneHot = {\"train\": df_train_dummy, \"test\": df_test_dummy}\n",
    "with open(HotFile, 'wb') as f:\n",
    "    pickle.dump(OneHot, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emperical Bayesian\n",
    "The second encode method is Emperical Bayesian to encode the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from itertools import product\n",
    "\n",
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=5, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    "\n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "\n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    "\n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    "\n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    "\n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    "\n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    "\n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg({'mean': 'mean', 'beta': 'size'})\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    "\n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    "\n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = pd.concat((df_train.loc[:,categorical],df_test.loc[:,categorical]),ignore_index=True )\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_f = []\n",
    "le = LabelEncoder()\n",
    "for c in categorical:\n",
    "    le.fit(total[c])\n",
    "    df_train[c+\"_num\"] = le.transform(df_train[c])\n",
    "    df_test[c+\"_num\"] = le.transform(df_test[c])\n",
    "    cat_f.append(c+\"_num\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "me = MeanEncoder(categorical_features=cat_f,n_splits=10,target_type='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_mean = me.fit_transform(df_train, df_train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_mean = me.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_cat = [ f+\"_pred\" for f in cat_f]\n",
    "total = new_cat + numerical\n",
    "df_train_mean = df_train_mean[total]\n",
    "df_test_mean = df_test_mean[total[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BayesianFile = modified + \"BayesianRaw.pkl\"\n",
    "Bayesian = {\"train\": df_train_mean, \"test\": df_test_mean}\n",
    "with open(BayesianFile, 'wb') as f:\n",
    "    pickle.dump(Bayesian, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
